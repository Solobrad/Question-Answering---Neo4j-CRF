{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifies intents and recognizes named entities for user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n:\\Year 3\\NLP\\Assignment2\\myenv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.layers import CRF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from neo4j import GraphDatabase\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intent classification model\n",
    "intent_model = load_model('Trained Models/intent_classification_model.h5', compile=False)\n",
    "intent_model.load_weights('Trained Models/intent_classification_weights.h5')\n",
    "\n",
    "learning_rate = 0.0001\n",
    "nadam = tf.keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "intent_model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "\n",
    "with open(f\"Trained Models/tokenizer.pkl\", 'rb') as f:\n",
    "    Tokenizer = pickle.load(f)\n",
    "\n",
    "    \n",
    "# Load NER model\n",
    "ner_model = tf.keras.models.load_model(\"Trained Models/Ner_BiLSTM_CRF\", custom_objects={'CRF': CRF})\n",
    "\n",
    "with open(f\"Trained Models/word2index.pkl\", 'rb') as f:\n",
    "    word2index = pickle.load(f)\n",
    "\n",
    "with open(f\"Trained Models/index2tag.pkl\", 'rb') as f:\n",
    "    index2tag = pickle.load(f)\n",
    "\n",
    "with open(f\"Trained Models/max_sentence.pkl\", 'rb') as f:\n",
    "    MAX_SENTENCE = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 783ms/step\n",
      "Where          : O    \n",
      "is             : O    \n",
      "Grand          : B-org\n",
      "Street         : B-org\n",
      "located        : O    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Where is Grand Street located?\"\n",
    "\n",
    "re_tok = re.compile(f\"([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])\")\n",
    "sentence = re_tok.sub(r\"  \", sentence).split()\n",
    "\n",
    "padded_sentence = sentence + [word2index[\"--PADDING--\"]] * (MAX_SENTENCE - len(sentence))\n",
    "padded_sentence = [word2index.get(w, 0) for w in padded_sentence]\n",
    "\n",
    "pred = ner_model.predict(np.array([padded_sentence]))\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "retval = \"\"\n",
    "for w, p in zip(sentence, pred[0]):\n",
    "    retval = retval + \"{:15}: {:5}\".format(w, index2tag[p]) + \"\\n\"\n",
    "\n",
    "print(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 401ms/step\n",
      "[[9.9658465e-01 2.4312774e-03 5.0097728e-06 3.5526366e-06 9.7547309e-04]]\n",
      "Result: scientific contributions\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and padding process\n",
    "phrase = \"What did Marie Curie discover?\"\n",
    "tokens = Tokenizer.texts_to_sequences([phrase])\n",
    "tokens = pad_sequences(tokens, maxlen=100)\n",
    "prediction = intent_model.predict(np.array(tokens))\n",
    "\n",
    "i,j = np.where(prediction == prediction.max()) #calculates the index of the maximum element of the array across all axis\n",
    "# i->rows, j->columns\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "\n",
    "print(prediction)\n",
    "total_possible_outcomes = [\n",
    "    \"scientific contributions\",      # Major discoveries and inventions\n",
    "    \"affiliations and locations\",    # Institutions and places where she worked\n",
    "    \"awards and recognitions\",       # Prizes and honors she received\n",
    "    \"biography\",                     # Information about her life and background\n",
    "    \"influences and impact\"          # Her influence on science and legacy\n",
    "]\n",
    "print(\"Result:\",total_possible_outcomes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = {\n",
    "    \"scientific contributions\": \"scientific contributions\",\n",
    "    \"affiliations and locations\": \"affiliations and locations\",\n",
    "    \"awards and recognitions\": \"awards and recognitions\",\n",
    "    \"biography\": \"biography\",\n",
    "    \"influences and impact\": \"influences and impact\"\n",
    "}\n",
    "\n",
    "def construct_neo4j_query(intent, entity):\n",
    "    relationship_type = intents.get(intent)\n",
    "    if not relationship_type:\n",
    "        raise ValueError(\"The intent you try to search is unfound\")\n",
    "    \n",
    "    if intent == \"scientific contributions\":\n",
    "        query = f\"\"\"\n",
    "        MATCH (n)-[r:RELATION]->(m)\n",
    "        WHERE n.title = $entity AND r.type IN ['discoverer', 'named']\n",
    "        RETURN m.title AS title\n",
    "        UNION\n",
    "        MATCH (n)<-[r:RELATION]-(m)\n",
    "        WHERE m.title = $entity AND r.type IN ['discoverer', 'named']\n",
    "        RETURN n.title AS title\n",
    "        \"\"\"\n",
    "    elif intent == \"affiliations and locations\":\n",
    "        query = f\"\"\"\n",
    "        MATCH (n)-[r:RELATION]->(m)\n",
    "        WHERE n.title = $entity AND r.type IN ['located']\n",
    "        RETURN m.title AS title\n",
    "        UNION\n",
    "        MATCH (n)<-[r:RELATION]-(m)\n",
    "        WHERE m.title = $entity AND r.type IN ['located']\n",
    "        RETURN n.title AS title\n",
    "        \"\"\"\n",
    "    elif intent == \"awards and recognitions\":\n",
    "        query = f\"\"\"\n",
    "        MATCH (n)-[r:`award received`]->(m)\n",
    "        WHERE n.title = $entity\n",
    "        RETURN m.title AS title\n",
    "        UNION\n",
    "        MATCH (n)<-[r:`award received`]-(m)\n",
    "        WHERE m.title = $entity\n",
    "        RETURN n.title AS title\n",
    "        \"\"\"\n",
    "\n",
    "    elif intent == \"biography\":\n",
    "        query = f\"\"\"\n",
    "        MATCH (n)-[r:RELATION]->(m)\n",
    "        WHERE n.title = $entity AND r.type IN ['biography']\n",
    "        RETURN m.title AS title\n",
    "        UNION\n",
    "        MATCH (n)<-[r:RELATION]-(m)\n",
    "        WHERE m.title = $entity AND r.type IN ['biography']\n",
    "        RETURN n.title AS title\n",
    "        \"\"\"\n",
    "    elif intent == \"influences and impact\":\n",
    "        query = f\"\"\"\n",
    "        MATCH (n)-[r:RELATION]->(m)\n",
    "        WHERE n.title = $entity AND r.type IN ['influence', 'impact']\n",
    "        RETURN m.title AS title\n",
    "        UNION\n",
    "        MATCH (n)<-[r:RELATION]-(m)\n",
    "        WHERE m.title = $entity AND r.type IN ['influence', 'impact']\n",
    "        RETURN n.title AS title\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Intent not supported for query construction.\")\n",
    "    \n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "uri = os.getenv('NEO4J_URI')\n",
    "neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(neo4j_username, neo4j_password))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_neo4j_query(query, entity):\n",
    "    def get_results(tx, query, entity):\n",
    "        \n",
    "        print(f\"Executing Query: {query} with entity: {entity}\")\n",
    "\n",
    "        result = tx.run(query, entity=entity)\n",
    "        return [record[\"title\"] for record in result]\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        results = session.execute_read(get_results, query, entity)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def retrieve_information(intent, entity):\n",
    "    query = construct_neo4j_query(intent, entity)\n",
    "    results = execute_neo4j_query(query, entity)\n",
    "    \n",
    "    if not results:  # If no results, try with lowercase entity\n",
    "        entity = entity.lower()\n",
    "        query = construct_neo4j_query(intent, entity)\n",
    "        results = execute_neo4j_query(query, entity)\n",
    "    \n",
    "    return format_response(entity, intent, results)\n",
    "\n",
    "def format_response(entity, intent, results):\n",
    "    if not results:\n",
    "            return f\"No information found for '{entity}' regarding '{intent}'.\"\n",
    "        \n",
    "    if intent == \"scientific contributions\":\n",
    "            return f\"{entity} is known for the following scientific contributions: {', '.join(results)}.\"\n",
    "    elif intent == \"affiliations and locations\":\n",
    "            return f\"{entity} was affiliated with the following institutions and locations: {', '.join(results)}.\"\n",
    "    elif intent == \"awards and recognitions\":\n",
    "            return f\"{entity} received the following awards and recognitions: {', '.join(results)}.\"\n",
    "    elif intent == \"biography\":\n",
    "            return f\"Information about {entity}'s life and background: {', '.join(results)}.\"\n",
    "    elif intent == \"influences and impact\":\n",
    "            return f\"{entity} had the following influences and impact: {', '.join(results)}.\"\n",
    "    else:\n",
    "            return f\"The information for {entity} regarding '{intent}' is {', '.join(results)}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(sentence):\n",
    "    tokens = Tokenizer.texts_to_sequences([sentence])\n",
    "    tokens = pad_sequences(tokens, maxlen=100)\n",
    "    prediction = intent_model.predict(np.array(tokens))\n",
    "\n",
    "    i, j = np.where(prediction == prediction.max())\n",
    "    i = int(i)\n",
    "    j = int(j)\n",
    "\n",
    "    total_possible_outcomes = [    \n",
    "    \"scientific contributions\",      \n",
    "    \"affiliations and locations\",  \n",
    "    \"awards and recognitions\",      \n",
    "    \"biography\",                     \n",
    "    \"influences and impact\"    \n",
    "    ]\n",
    "    return total_possible_outcomes[j]\n",
    "\n",
    "def predict_ne(sentence):\n",
    "    re_tok = re.compile(f\"([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])\")\n",
    "    sentence = re_tok.sub(r\"  \", sentence).split()\n",
    "\n",
    "    # Pad the sentence to the maximum length\n",
    "    padded_sentence = sentence + [word2index[\"--PADDING--\"]] * (MAX_SENTENCE - len(sentence))\n",
    "    padded_sentence = [word2index.get(w, 0) for w in padded_sentence]\n",
    "\n",
    "    # Predict entities using the NER model\n",
    "    pred = ner_model.predict(np.array([padded_sentence]))\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_label = None\n",
    "\n",
    "    for w, p in zip(sentence, pred[0]):\n",
    "        tag = index2tag[p]\n",
    "        if tag.startswith(\"B-\") or (tag.startswith(\"I-\") and current_label != tag[2:]):\n",
    "            if current_entity and current_label:\n",
    "                entities.append({'entity': current_label, 'text': \" \".join(current_entity)})\n",
    "            current_entity = [w]\n",
    "            current_label = tag[2:]\n",
    "        elif tag.startswith(\"I-\") and current_label == tag[2:]:\n",
    "            current_entity.append(w)\n",
    "        else:\n",
    "            if current_entity and current_label:\n",
    "                entities.append({'entity': current_label, 'text': \" \".join(current_entity)})\n",
    "            current_entity = []\n",
    "            current_label = None\n",
    "\n",
    "    if current_entity and current_label:\n",
    "        entities.append({'entity': current_label, 'text': \" \".join(current_entity)})\n",
    "\n",
    "    # Return the entities as a list of dictionaries\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Intent: awards and recognitions\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Entities: [{'entity': 'per', 'text': 'Marie'}, {'entity': 'org', 'text': 'Curie'}]\n",
      "Entity: Marie\n",
      "Executing Query: \n",
      "        MATCH (n)-[r:`award received`]->(m)\n",
      "        WHERE n.title = $entity\n",
      "        RETURN m.title AS title\n",
      "        UNION\n",
      "        MATCH (n)<-[r:`award received`]-(m)\n",
      "        WHERE m.title = $entity\n",
      "        RETURN n.title AS title\n",
      "         with entity: Marie\n",
      "Executing Query: \n",
      "        MATCH (n)-[r:`award received`]->(m)\n",
      "        WHERE n.title = $entity\n",
      "        RETURN m.title AS title\n",
      "        UNION\n",
      "        MATCH (n)<-[r:`award received`]-(m)\n",
      "        WHERE m.title = $entity\n",
      "        RETURN n.title AS title\n",
      "         with entity: marie\n",
      "No information found for 'marie' regarding 'awards and recognitions'.\n"
     ]
    }
   ],
   "source": [
    "Question = \"What awards did Marie Curie receive?\"\n",
    "\n",
    "# Classify intent\n",
    "intent = classify_intent(Question)\n",
    "print(f\"Intent: {intent}\")\n",
    "\n",
    "# Extract entities\n",
    "entities = predict_ne(Question)\n",
    "print(f\"Entities: {entities}\")\n",
    "\n",
    "if not entities:\n",
    "    print(\"No entities found.\")\n",
    "    response = \"No entities found in the provided phrase.\"\n",
    "else:\n",
    "    entity = entities[0]['text']\n",
    "    print(f\"Entity: {entity}\")\n",
    "    \n",
    "    query = construct_neo4j_query(intent, entity)\n",
    "    if query is None:\n",
    "        response = \"Failed to construct the query.\"\n",
    "    else:\n",
    "        response = retrieve_information(intent, entity)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Query: \n",
      "        MATCH (n)-[r:`award received`]->(m)\n",
      "        WHERE n.title = $entity\n",
      "        RETURN m.title AS title\n",
      "        UNION\n",
      "        MATCH (n)<-[r:`award received`]-(m)\n",
      "        WHERE m.title = $entity\n",
      "        RETURN n.title AS title\n",
      "         with entity: Marie Curie\n",
      "Marie Curie received the following awards and recognitions: Nobel Prize in Physics, Nobel Prize in Physics, Physics, and Henri Becquerel, Nobel Prize, Nobel Prize in Chemistry.\n"
     ]
    }
   ],
   "source": [
    "entity = \"Marie Curie\"\n",
    "intent = \"awards and recognitions\"\n",
    "\n",
    "# Construct the query\n",
    "query = construct_neo4j_query(intent, entity)\n",
    "\n",
    "# Execute the query and get results\n",
    "results = execute_neo4j_query(query, entity)\n",
    "\n",
    "# Format and print the response\n",
    "response = format_response(entity, intent, results)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (m:Entity)-[r:`award received`]->(n:Entity)\n",
    "# WHERE m.title = 'Marie Curie' AND n.title = 'Nobel Prize in Chemistry'\n",
    "# RETURN m, r, n\n",
    "\n",
    "# MATCH (m:Entity)-[r:`award received`]->(n:Entity)\n",
    "# WHERE m.title = 'Marie Curie'\n",
    "# RETURN DISTINCT n.title AS Award\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
